{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e43cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "import joblib\n",
    "from sympy import symbols, diff\n",
    "from matplotlib.widgets import Slider, Button\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib\n",
    "from ForceInfer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cd530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '0.75Pa15p_cleared.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437fe429",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5813a8",
   "metadata": {},
   "source": [
    "We are going to use the file '0.75Pa15p_cleared.csv' as a demonstration of how to use the model. First let's specify some parameters in this data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1267cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_begin = [.4] # Used for train-validation split. The percentage of validation data is always 10% and begins at this number. \n",
    "tau = 16 # how many frames used in the intergral of weak formation\n",
    "nparticles = 15 # number of particles in this data\n",
    "ndim = 4 # information for each particle, includes x, y, z and descriptor. If you want multi-dimension discriptors, you may go\n",
    "# to the get_data function, and change n_dm \n",
    "n_out = 2 # the model only infers force in x_y plane, 2 dimensions. \n",
    "method = 'mean' # the method used to calculate the descriptor of each particles. You can also use 'std' for std(z_i) or a \n",
    "# callable, for example: method = np.mean\n",
    "scale = 1 # the scale multiplied to the descriptor to make it more or less significant as an input to the model\n",
    "deltat = 0.005 # the time interval between frames\n",
    "\n",
    "# Define the symbol t for sympy expression\n",
    "t = symbols('t')\n",
    "\n",
    "# Define the function weight function w which is a sympy expression involving t\n",
    "w = (t**2-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce5a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find zmm\n"
     ]
    }
   ],
   "source": [
    "#the data should have 5 columns, each representing  \n",
    "\n",
    "X1,X2,Y1,Y2 = get_data(fname,val_begin,w,tau,nparticles = nparticles,ndim = ndim,n_out = n_out,\n",
    "                       method = method,scale = scale, deltat = deltat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d65daf",
   "metadata": {},
   "source": [
    "Now we get the input of train, input of validation, output of train, output of validation for this model. Note that X1 is a tuple of two tensors. The first tensor is 3-dimensional, representing $t$, $t'$ and each particles' information ($x$, $y$, $z$, $s$) respectively, used for inferring interaction and confinement force. The second tensor is 2-dimensional, $w$ convolve $v$, which multiplied by $\\gamma$ is the damping The first dimension is $t$ and the second is $x$ or $y$. Y1 is 2-dimensional, $w$ convolve $a$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7cbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132870, 15, 60)\n",
      "(132870, 2)\n",
      "(132870, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X1[0].shape)\n",
    "print(X1[1].shape)\n",
    "print(Y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d45f02",
   "metadata": {},
   "source": [
    "Now we train the model. First we would want to set the parameter delta for huber loss to be 25% the std of training Y1 (we expect R^2 to be 0.99 so an average fitting error of 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091a2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = Y1.numpy().std()* 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed941b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/210\n",
      "1039/1039 [==============================] - 12s 8ms/step - loss: 140951.6719 - r2: 0.9258 - M: 424945.1875 - val_loss: 57931.9492 - val_r2: 0.9745 - val_M: 133159.1719\n",
      "Epoch 2/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 45243.7461 - r2: 0.9797 - M: 116062.5312 - val_loss: 98236.4531 - val_r2: 0.9576 - val_M: 221328.8125\n",
      "Epoch 3/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 32557.3652 - r2: 0.9851 - M: 85564.5312 - val_loss: 28891.6406 - val_r2: 0.9879 - val_M: 63024.4180\n",
      "Epoch 4/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 27143.8145 - r2: 0.9871 - M: 73664.2656 - val_loss: 31515.3516 - val_r2: 0.9867 - val_M: 69248.1328\n",
      "Epoch 5/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 24174.4062 - r2: 0.9884 - M: 66749.9453 - val_loss: 24138.3086 - val_r2: 0.9898 - val_M: 53320.6367\n",
      "Epoch 6/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 22189.6406 - r2: 0.9891 - M: 62241.5664 - val_loss: 44294.7500 - val_r2: 0.9819 - val_M: 94571.9141\n",
      "Epoch 7/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 20865.2695 - r2: 0.9896 - M: 59313.7500 - val_loss: 27612.4590 - val_r2: 0.9883 - val_M: 60929.5664\n",
      "Epoch 8/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 19808.9004 - r2: 0.9901 - M: 56894.4062 - val_loss: 23353.6016 - val_r2: 0.9899 - val_M: 52608.4609\n",
      "Epoch 9/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 18903.9922 - r2: 0.9905 - M: 54697.5156 - val_loss: 18643.8672 - val_r2: 0.9915 - val_M: 44418.2031\n",
      "Epoch 10/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 18226.2637 - r2: 0.9907 - M: 53255.0820 - val_loss: 19770.2695 - val_r2: 0.9911 - val_M: 46270.1719\n",
      "Epoch 11/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 17703.0371 - r2: 0.9909 - M: 52144.6875 - val_loss: 15908.4512 - val_r2: 0.9928 - val_M: 37804.0430\n",
      "Epoch 12/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 17680.9160 - r2: 0.9909 - M: 52205.0430 - val_loss: 20449.4941 - val_r2: 0.9910 - val_M: 47172.6328\n",
      "Epoch 13/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 17486.4160 - r2: 0.9910 - M: 51597.9023 - val_loss: 17743.6348 - val_r2: 0.9920 - val_M: 41720.1562\n",
      "Epoch 14/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 17249.8086 - r2: 0.9911 - M: 50996.8906 - val_loss: 15025.2383 - val_r2: 0.9930 - val_M: 36577.5273\n",
      "Epoch 15/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 17158.8242 - r2: 0.9911 - M: 50894.4844 - val_loss: 18883.3281 - val_r2: 0.9914 - val_M: 45021.2773\n",
      "Epoch 16/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16995.9805 - r2: 0.9912 - M: 50294.7031 - val_loss: 16210.2656 - val_r2: 0.9925 - val_M: 39132.5781\n",
      "Epoch 17/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16884.9746 - r2: 0.9912 - M: 50180.6992 - val_loss: 28194.4668 - val_r2: 0.9875 - val_M: 65136.9727\n",
      "Epoch 18/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16779.7461 - r2: 0.9912 - M: 50219.9180 - val_loss: 18291.0684 - val_r2: 0.9914 - val_M: 44952.6484\n",
      "Epoch 19/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16679.6465 - r2: 0.9913 - M: 49617.8984 - val_loss: 17745.3438 - val_r2: 0.9917 - val_M: 43296.2266\n",
      "Epoch 20/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16559.6973 - r2: 0.9914 - M: 49251.4609 - val_loss: 14926.7842 - val_r2: 0.9928 - val_M: 37644.4648\n",
      "Epoch 21/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16495.3906 - r2: 0.9914 - M: 49122.9062 - val_loss: 16774.7930 - val_r2: 0.9922 - val_M: 40575.8984\n",
      "Epoch 22/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16398.1914 - r2: 0.9915 - M: 48792.5742 - val_loss: 15279.4717 - val_r2: 0.9927 - val_M: 38316.1523\n",
      "Epoch 23/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16314.5693 - r2: 0.9915 - M: 48621.7070 - val_loss: 18240.1309 - val_r2: 0.9915 - val_M: 44420.1211\n",
      "Epoch 24/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16229.8682 - r2: 0.9915 - M: 48376.1211 - val_loss: 19711.7148 - val_r2: 0.9908 - val_M: 47765.8242\n",
      "Epoch 25/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16143.3350 - r2: 0.9916 - M: 48202.8008 - val_loss: 22220.5586 - val_r2: 0.9899 - val_M: 52677.6914\n",
      "Epoch 26/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 16034.8164 - r2: 0.9916 - M: 47883.7852 - val_loss: 14917.7188 - val_r2: 0.9926 - val_M: 38404.5273\n",
      "Epoch 27/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15972.5625 - r2: 0.9916 - M: 47807.2031 - val_loss: 17545.6973 - val_r2: 0.9917 - val_M: 43559.5391\n",
      "Epoch 28/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15928.7539 - r2: 0.9917 - M: 47607.3398 - val_loss: 18140.8164 - val_r2: 0.9915 - val_M: 44500.2812\n",
      "Epoch 29/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15840.9678 - r2: 0.9917 - M: 47381.2227 - val_loss: 14341.3652 - val_r2: 0.9929 - val_M: 36813.7383\n",
      "Epoch 30/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15748.6426 - r2: 0.9918 - M: 47123.3320 - val_loss: 16930.1074 - val_r2: 0.9918 - val_M: 42830.4062\n",
      "Epoch 31/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15682.5664 - r2: 0.9918 - M: 46907.3242 - val_loss: 13314.4131 - val_r2: 0.9933 - val_M: 35044.4922\n",
      "Epoch 32/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15619.1904 - r2: 0.9918 - M: 46797.2266 - val_loss: 13844.4385 - val_r2: 0.9931 - val_M: 36187.6016\n",
      "Epoch 33/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15527.0664 - r2: 0.9918 - M: 46673.3594 - val_loss: 17194.0000 - val_r2: 0.9915 - val_M: 44110.9336\n",
      "Epoch 34/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15445.1748 - r2: 0.9919 - M: 46350.7070 - val_loss: 16350.9209 - val_r2: 0.9921 - val_M: 41077.8477\n",
      "Epoch 35/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15406.4199 - r2: 0.9919 - M: 46178.0781 - val_loss: 15133.1680 - val_r2: 0.9923 - val_M: 40120.7969\n",
      "Epoch 36/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15335.0566 - r2: 0.9920 - M: 45980.8789 - val_loss: 15558.8594 - val_r2: 0.9924 - val_M: 39709.1133\n",
      "Epoch 37/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15267.3857 - r2: 0.9920 - M: 45794.8984 - val_loss: 13796.7939 - val_r2: 0.9929 - val_M: 37028.2930\n",
      "Epoch 38/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15197.3779 - r2: 0.9920 - M: 45634.4883 - val_loss: 16800.1309 - val_r2: 0.9917 - val_M: 43553.4414\n",
      "Epoch 39/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 15141.5879 - r2: 0.9920 - M: 45604.0078 - val_loss: 15970.6006 - val_r2: 0.9919 - val_M: 42156.3008\n",
      "Epoch 40/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 15116.5254 - r2: 0.9921 - M: 45398.9961 - val_loss: 15067.8740 - val_r2: 0.9924 - val_M: 39829.5664\n",
      "Epoch 41/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 15000.4893 - r2: 0.9921 - M: 45083.0000 - val_loss: 13729.7227 - val_r2: 0.9930 - val_M: 36602.9023\n",
      "Epoch 42/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14993.1973 - r2: 0.9921 - M: 45091.8633 - val_loss: 15003.1338 - val_r2: 0.9925 - val_M: 39270.4609\n",
      "Epoch 43/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14951.9941 - r2: 0.9921 - M: 44999.0625 - val_loss: 13840.5342 - val_r2: 0.9929 - val_M: 37030.8984\n",
      "Epoch 44/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14908.1904 - r2: 0.9922 - M: 44853.3789 - val_loss: 13073.9268 - val_r2: 0.9932 - val_M: 35328.2109\n",
      "Epoch 45/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14858.6016 - r2: 0.9922 - M: 44750.3203 - val_loss: 17216.9707 - val_r2: 0.9915 - val_M: 44124.4258\n",
      "Epoch 46/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14832.0527 - r2: 0.9922 - M: 44633.5820 - val_loss: 13820.9268 - val_r2: 0.9928 - val_M: 37736.6367\n",
      "Epoch 47/210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14784.2803 - r2: 0.9922 - M: 44546.1797 - val_loss: 17017.2188 - val_r2: 0.9915 - val_M: 44469.8555\n",
      "Epoch 48/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14722.2266 - r2: 0.9923 - M: 44211.7812 - val_loss: 13092.0820 - val_r2: 0.9930 - val_M: 36515.3789\n",
      "Epoch 49/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14715.8594 - r2: 0.9923 - M: 44200.4883 - val_loss: 13786.2246 - val_r2: 0.9929 - val_M: 37235.0625\n",
      "Epoch 50/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14679.4668 - r2: 0.9923 - M: 44186.2852 - val_loss: 14152.5752 - val_r2: 0.9928 - val_M: 37719.0156\n",
      "Epoch 51/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14623.7783 - r2: 0.9923 - M: 44050.6641 - val_loss: 14609.1924 - val_r2: 0.9926 - val_M: 38502.0820\n",
      "Epoch 52/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14589.1982 - r2: 0.9923 - M: 43865.9727 - val_loss: 17089.2109 - val_r2: 0.9915 - val_M: 44595.4922\n",
      "Epoch 53/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14550.6143 - r2: 0.9924 - M: 43738.6328 - val_loss: 13756.2266 - val_r2: 0.9928 - val_M: 37357.1328\n",
      "Epoch 54/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14537.5029 - r2: 0.9924 - M: 43709.3281 - val_loss: 15244.0557 - val_r2: 0.9922 - val_M: 40778.8711\n",
      "Epoch 55/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14520.5742 - r2: 0.9924 - M: 43635.2227 - val_loss: 17637.6855 - val_r2: 0.9913 - val_M: 45234.3438\n",
      "Epoch 56/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14495.5430 - r2: 0.9924 - M: 43674.0312 - val_loss: 15040.6260 - val_r2: 0.9922 - val_M: 40886.7891\n",
      "Epoch 57/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14456.0479 - r2: 0.9924 - M: 43465.9141 - val_loss: 13410.8799 - val_r2: 0.9928 - val_M: 37489.3281\n",
      "Epoch 58/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14428.0420 - r2: 0.9924 - M: 43342.8672 - val_loss: 12686.2256 - val_r2: 0.9930 - val_M: 36343.5391\n",
      "Epoch 59/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14409.7256 - r2: 0.9924 - M: 43298.3008 - val_loss: 14517.0820 - val_r2: 0.9923 - val_M: 40018.1680\n",
      "Epoch 60/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14360.6221 - r2: 0.9924 - M: 43296.0664 - val_loss: 15376.0078 - val_r2: 0.9922 - val_M: 40843.5039\n",
      "Epoch 61/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14353.6406 - r2: 0.9925 - M: 43097.8555 - val_loss: 13602.7412 - val_r2: 0.9928 - val_M: 37449.7500\n",
      "Epoch 62/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14336.1924 - r2: 0.9925 - M: 43091.1445 - val_loss: 14926.5254 - val_r2: 0.9923 - val_M: 40390.9414\n",
      "Epoch 63/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14306.9248 - r2: 0.9925 - M: 43016.6133 - val_loss: 15911.2324 - val_r2: 0.9921 - val_M: 41453.5742\n",
      "Epoch 64/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14288.8867 - r2: 0.9925 - M: 42990.1719 - val_loss: 12960.3115 - val_r2: 0.9929 - val_M: 36850.6406\n",
      "Epoch 65/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14263.7959 - r2: 0.9925 - M: 42831.2031 - val_loss: 14666.7188 - val_r2: 0.9925 - val_M: 39046.3945\n",
      "Epoch 66/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14259.7773 - r2: 0.9925 - M: 42810.2461 - val_loss: 13090.1660 - val_r2: 0.9929 - val_M: 37082.3516\n",
      "Epoch 67/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14234.1182 - r2: 0.9925 - M: 42803.7617 - val_loss: 14212.7422 - val_r2: 0.9923 - val_M: 40243.8672\n",
      "Epoch 68/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14211.8496 - r2: 0.9925 - M: 42653.2266 - val_loss: 12886.3936 - val_r2: 0.9930 - val_M: 36497.5039\n",
      "Epoch 69/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14196.0146 - r2: 0.9925 - M: 42657.8633 - val_loss: 12173.6074 - val_r2: 0.9933 - val_M: 34971.0820\n",
      "Epoch 70/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14180.5527 - r2: 0.9926 - M: 42534.4180 - val_loss: 12690.6182 - val_r2: 0.9930 - val_M: 36385.4766\n",
      "Epoch 71/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14155.3418 - r2: 0.9926 - M: 42548.9375 - val_loss: 14008.8301 - val_r2: 0.9926 - val_M: 38665.7500\n",
      "Epoch 72/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14152.4697 - r2: 0.9926 - M: 42473.6406 - val_loss: 15123.1133 - val_r2: 0.9921 - val_M: 41292.8672\n",
      "Epoch 73/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14134.7061 - r2: 0.9926 - M: 42429.9141 - val_loss: 13266.5068 - val_r2: 0.9928 - val_M: 37466.0586\n",
      "Epoch 74/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14114.2783 - r2: 0.9926 - M: 42333.8398 - val_loss: 13242.3320 - val_r2: 0.9929 - val_M: 37094.4492\n",
      "Epoch 75/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14087.8047 - r2: 0.9926 - M: 42312.4023 - val_loss: 12690.1299 - val_r2: 0.9929 - val_M: 36826.9688\n",
      "Epoch 76/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14084.1963 - r2: 0.9926 - M: 42311.0898 - val_loss: 13153.8760 - val_r2: 0.9928 - val_M: 37527.1133\n",
      "Epoch 77/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14071.5684 - r2: 0.9926 - M: 42204.3086 - val_loss: 13558.8799 - val_r2: 0.9927 - val_M: 37999.3477\n",
      "Epoch 78/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14057.9160 - r2: 0.9926 - M: 42139.2617 - val_loss: 12609.8066 - val_r2: 0.9930 - val_M: 36728.0234\n",
      "Epoch 79/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14033.4365 - r2: 0.9926 - M: 42111.1328 - val_loss: 13678.2041 - val_r2: 0.9925 - val_M: 39123.4023\n",
      "Epoch 80/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14021.0195 - r2: 0.9927 - M: 42022.5234 - val_loss: 12711.5146 - val_r2: 0.9929 - val_M: 37215.2773\n",
      "Epoch 81/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14009.0693 - r2: 0.9927 - M: 42040.7109 - val_loss: 13488.9336 - val_r2: 0.9927 - val_M: 38112.4336\n",
      "Epoch 82/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 14005.9756 - r2: 0.9927 - M: 41982.8828 - val_loss: 12471.7568 - val_r2: 0.9931 - val_M: 35764.8008\n",
      "Epoch 83/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13987.5176 - r2: 0.9927 - M: 41941.7734 - val_loss: 12497.9062 - val_r2: 0.9930 - val_M: 36271.8594\n",
      "Epoch 84/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13964.9209 - r2: 0.9927 - M: 41836.2188 - val_loss: 12471.9375 - val_r2: 0.9930 - val_M: 36375.6562\n",
      "Epoch 85/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13952.7236 - r2: 0.9927 - M: 41855.9219 - val_loss: 13007.7031 - val_r2: 0.9928 - val_M: 37399.0117\n",
      "Epoch 86/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13947.4668 - r2: 0.9927 - M: 41804.8203 - val_loss: 13830.5166 - val_r2: 0.9926 - val_M: 38822.6484\n",
      "Epoch 87/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13932.3105 - r2: 0.9927 - M: 41735.1953 - val_loss: 13151.8213 - val_r2: 0.9929 - val_M: 37209.3633\n",
      "Epoch 88/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13922.7002 - r2: 0.9927 - M: 41738.0234 - val_loss: 12616.2246 - val_r2: 0.9931 - val_M: 36155.1211\n",
      "Epoch 89/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13913.7363 - r2: 0.9927 - M: 41678.5820 - val_loss: 13020.1416 - val_r2: 0.9929 - val_M: 36900.3984\n",
      "Epoch 90/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13904.5508 - r2: 0.9927 - M: 41655.2500 - val_loss: 13060.2217 - val_r2: 0.9929 - val_M: 37141.4297\n",
      "Epoch 91/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13901.9736 - r2: 0.9925 - M: 42916.4258 - val_loss: 12789.1406 - val_r2: 0.9928 - val_M: 37517.8008\n",
      "Epoch 92/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13889.0820 - r2: 0.9927 - M: 41580.2031 - val_loss: 12945.1973 - val_r2: 0.9929 - val_M: 36995.6992\n",
      "Epoch 93/210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13870.6631 - r2: 0.9927 - M: 41553.2773 - val_loss: 12917.6387 - val_r2: 0.9929 - val_M: 37137.9648\n",
      "Epoch 94/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13862.0703 - r2: 0.9928 - M: 41525.6289 - val_loss: 12506.6709 - val_r2: 0.9930 - val_M: 36760.3711\n",
      "Epoch 95/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13848.2402 - r2: 0.9928 - M: 41489.2266 - val_loss: 12153.3535 - val_r2: 0.9933 - val_M: 35015.4883\n",
      "Epoch 96/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13845.0674 - r2: 0.9928 - M: 41451.6406 - val_loss: 13333.1846 - val_r2: 0.9927 - val_M: 37910.5781\n",
      "Epoch 97/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13833.0762 - r2: 0.9928 - M: 41395.3281 - val_loss: 12635.8252 - val_r2: 0.9931 - val_M: 36217.5781\n",
      "Epoch 98/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13828.9766 - r2: 0.9928 - M: 41378.4258 - val_loss: 13092.3818 - val_r2: 0.9927 - val_M: 38333.1719\n",
      "Epoch 99/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13814.8984 - r2: 0.9928 - M: 41344.8711 - val_loss: 12469.8428 - val_r2: 0.9930 - val_M: 36379.9688\n",
      "Epoch 100/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13800.3418 - r2: 0.9928 - M: 41247.4961 - val_loss: 14336.8086 - val_r2: 0.9924 - val_M: 39753.9336\n",
      "Epoch 101/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13801.5137 - r2: 0.9926 - M: 42187.3711 - val_loss: 13259.7275 - val_r2: 0.9927 - val_M: 38313.0703\n",
      "Epoch 102/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13766.2373 - r2: 0.9928 - M: 41088.3984 - val_loss: 12633.5342 - val_r2: 0.9929 - val_M: 36891.5117\n",
      "Epoch 103/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13769.8018 - r2: 0.9928 - M: 41164.4141 - val_loss: 13048.4951 - val_r2: 0.9928 - val_M: 37750.2422\n",
      "Epoch 104/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13777.0479 - r2: 0.9928 - M: 41229.2344 - val_loss: 12271.4053 - val_r2: 0.9930 - val_M: 36295.7578\n",
      "Epoch 105/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13756.0195 - r2: 0.9928 - M: 41097.5781 - val_loss: 12315.6973 - val_r2: 0.9931 - val_M: 36253.9219\n",
      "Epoch 106/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13751.1826 - r2: 0.9928 - M: 41174.2969 - val_loss: 13114.2109 - val_r2: 0.9928 - val_M: 37627.8477\n",
      "Epoch 107/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13739.6074 - r2: 0.9928 - M: 41096.3477 - val_loss: 12771.1494 - val_r2: 0.9929 - val_M: 37241.7734\n",
      "Epoch 108/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13734.8242 - r2: 0.9928 - M: 41007.1484 - val_loss: 12776.1240 - val_r2: 0.9928 - val_M: 37523.0508\n",
      "Epoch 109/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13729.7002 - r2: 0.9928 - M: 41055.3320 - val_loss: 12675.1807 - val_r2: 0.9928 - val_M: 37477.8516\n",
      "Epoch 110/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13718.5049 - r2: 0.9928 - M: 41019.4102 - val_loss: 12548.8486 - val_r2: 0.9929 - val_M: 36923.0430\n",
      "Epoch 111/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13717.6689 - r2: 0.9928 - M: 40969.7344 - val_loss: 12497.9941 - val_r2: 0.9930 - val_M: 36489.4258\n",
      "Epoch 112/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13700.1602 - r2: 0.9929 - M: 40951.8359 - val_loss: 13170.0938 - val_r2: 0.9927 - val_M: 38260.5156\n",
      "Epoch 113/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13688.2549 - r2: 0.9929 - M: 40876.0781 - val_loss: 12746.2041 - val_r2: 0.9929 - val_M: 36847.9922\n",
      "Epoch 114/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13688.5908 - r2: 0.9928 - M: 41001.1953 - val_loss: 12576.6152 - val_r2: 0.9930 - val_M: 36639.8672\n",
      "Epoch 115/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13688.0371 - r2: 0.9929 - M: 40839.9844 - val_loss: 12652.0000 - val_r2: 0.9929 - val_M: 36983.7109\n",
      "Epoch 116/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13668.2002 - r2: 0.9929 - M: 40812.9922 - val_loss: 12364.3955 - val_r2: 0.9930 - val_M: 36347.0078\n",
      "Epoch 117/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13668.9150 - r2: 0.9929 - M: 40844.3359 - val_loss: 12364.3057 - val_r2: 0.9930 - val_M: 36499.2539\n",
      "Epoch 118/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13663.9424 - r2: 0.9929 - M: 40784.6914 - val_loss: 12775.7461 - val_r2: 0.9928 - val_M: 37684.6172\n",
      "Epoch 119/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13649.5420 - r2: 0.9929 - M: 40730.9023 - val_loss: 12463.1182 - val_r2: 0.9928 - val_M: 37453.0703\n",
      "Epoch 120/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13649.7188 - r2: 0.9929 - M: 40735.7969 - val_loss: 12368.7930 - val_r2: 0.9930 - val_M: 36749.5156\n",
      "Epoch 121/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13641.4844 - r2: 0.9929 - M: 40726.7656 - val_loss: 12875.6221 - val_r2: 0.9928 - val_M: 37539.8203\n",
      "Epoch 122/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13639.2773 - r2: 0.9929 - M: 40669.7148 - val_loss: 12171.0645 - val_r2: 0.9931 - val_M: 36231.0312\n",
      "Epoch 123/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13626.4023 - r2: 0.9929 - M: 40625.2500 - val_loss: 12408.3740 - val_r2: 0.9930 - val_M: 36510.0742\n",
      "Epoch 124/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13619.1094 - r2: 0.9929 - M: 40619.9336 - val_loss: 12775.5889 - val_r2: 0.9928 - val_M: 37721.2109\n",
      "Epoch 125/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13619.6133 - r2: 0.9929 - M: 40611.8789 - val_loss: 12064.6953 - val_r2: 0.9931 - val_M: 36072.6250\n",
      "Epoch 126/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13615.1631 - r2: 0.9929 - M: 40641.0898 - val_loss: 12338.6748 - val_r2: 0.9929 - val_M: 36831.6641\n",
      "Epoch 127/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13603.6123 - r2: 0.9929 - M: 40629.8711 - val_loss: 12939.9658 - val_r2: 0.9928 - val_M: 37504.5781\n",
      "Epoch 128/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13589.0869 - r2: 0.9929 - M: 40490.5938 - val_loss: 12194.0840 - val_r2: 0.9931 - val_M: 36209.4336\n",
      "Epoch 129/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13600.2578 - r2: 0.9929 - M: 40578.4297 - val_loss: 12535.8809 - val_r2: 0.9929 - val_M: 37220.3867\n",
      "Epoch 130/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13585.0947 - r2: 0.9929 - M: 40493.0742 - val_loss: 12278.7217 - val_r2: 0.9929 - val_M: 36858.4883\n",
      "Epoch 131/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13581.8330 - r2: 0.9929 - M: 40502.3555 - val_loss: 12115.1719 - val_r2: 0.9929 - val_M: 36801.2891\n",
      "Epoch 132/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13579.9287 - r2: 0.9929 - M: 40486.4648 - val_loss: 12177.2744 - val_r2: 0.9930 - val_M: 36333.5547\n",
      "Epoch 133/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13574.5791 - r2: 0.9929 - M: 40437.1836 - val_loss: 12580.6826 - val_r2: 0.9928 - val_M: 37709.7539\n",
      "Epoch 134/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13565.5000 - r2: 0.9929 - M: 40373.9258 - val_loss: 12485.5967 - val_r2: 0.9929 - val_M: 36881.2773\n",
      "Epoch 135/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13564.6357 - r2: 0.9929 - M: 40438.5273 - val_loss: 11921.7344 - val_r2: 0.9931 - val_M: 35769.9609\n",
      "Epoch 136/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13561.6670 - r2: 0.9929 - M: 40428.9492 - val_loss: 12118.7207 - val_r2: 0.9931 - val_M: 36237.9844\n",
      "Epoch 137/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13550.5898 - r2: 0.9930 - M: 40343.2812 - val_loss: 12180.2217 - val_r2: 0.9931 - val_M: 36185.4492\n",
      "Epoch 138/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13547.4844 - r2: 0.9929 - M: 40365.5039 - val_loss: 12145.3340 - val_r2: 0.9930 - val_M: 36393.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13543.5508 - r2: 0.9929 - M: 40366.4180 - val_loss: 12459.1455 - val_r2: 0.9929 - val_M: 36984.9883\n",
      "Epoch 140/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13537.3125 - r2: 0.9930 - M: 40341.0273 - val_loss: 12211.8203 - val_r2: 0.9931 - val_M: 36221.0391\n",
      "Epoch 141/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13534.0146 - r2: 0.9930 - M: 40320.8828 - val_loss: 12227.7188 - val_r2: 0.9930 - val_M: 36595.4219\n",
      "Epoch 142/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13535.6807 - r2: 0.9930 - M: 40308.2227 - val_loss: 12495.7422 - val_r2: 0.9929 - val_M: 37212.0391\n",
      "Epoch 143/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13529.3555 - r2: 0.9930 - M: 40301.1680 - val_loss: 12398.8652 - val_r2: 0.9929 - val_M: 36924.4414\n",
      "Epoch 144/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13523.8096 - r2: 0.9930 - M: 40280.9297 - val_loss: 12316.9834 - val_r2: 0.9930 - val_M: 36469.7227\n",
      "Epoch 145/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13518.0752 - r2: 0.9930 - M: 40292.7852 - val_loss: 12468.3457 - val_r2: 0.9928 - val_M: 37391.9180\n",
      "Epoch 146/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13515.5381 - r2: 0.9930 - M: 40239.5234 - val_loss: 12052.6377 - val_r2: 0.9930 - val_M: 36505.7930\n",
      "Epoch 147/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13512.5449 - r2: 0.9930 - M: 40172.5352 - val_loss: 12146.9551 - val_r2: 0.9931 - val_M: 36158.0117\n",
      "Epoch 148/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13504.8018 - r2: 0.9930 - M: 40220.6055 - val_loss: 12242.2588 - val_r2: 0.9930 - val_M: 36688.9531\n",
      "Epoch 149/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13503.2207 - r2: 0.9930 - M: 40188.2109 - val_loss: 12177.8232 - val_r2: 0.9930 - val_M: 36407.9609\n",
      "Epoch 150/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13501.2520 - r2: 0.9930 - M: 40191.7695 - val_loss: 12339.7471 - val_r2: 0.9930 - val_M: 36763.7891\n",
      "Epoch 151/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13484.7500 - r2: 0.9930 - M: 40157.2422 - val_loss: 12034.8887 - val_r2: 0.9931 - val_M: 36062.7383\n",
      "Epoch 152/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13478.3320 - r2: 0.9930 - M: 40120.0820 - val_loss: 12213.6914 - val_r2: 0.9929 - val_M: 36797.8789\n",
      "Epoch 153/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13470.9229 - r2: 0.9930 - M: 40106.6016 - val_loss: 12006.8506 - val_r2: 0.9930 - val_M: 36366.9922\n",
      "Epoch 154/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13466.6963 - r2: 0.9930 - M: 40095.7578 - val_loss: 12073.0527 - val_r2: 0.9930 - val_M: 36551.6523\n",
      "Epoch 155/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13460.7637 - r2: 0.9930 - M: 40054.1445 - val_loss: 12099.6357 - val_r2: 0.9930 - val_M: 36499.5195\n",
      "Epoch 156/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13457.4941 - r2: 0.9930 - M: 40025.7500 - val_loss: 11951.0918 - val_r2: 0.9931 - val_M: 36181.4453\n",
      "Epoch 157/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13452.5186 - r2: 0.9930 - M: 40034.4492 - val_loss: 12282.2090 - val_r2: 0.9929 - val_M: 36891.5977\n",
      "Epoch 158/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13445.7471 - r2: 0.9930 - M: 40011.5117 - val_loss: 12321.1182 - val_r2: 0.9930 - val_M: 36665.9844\n",
      "Epoch 159/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13442.0527 - r2: 0.9930 - M: 39991.3359 - val_loss: 12083.0576 - val_r2: 0.9930 - val_M: 36556.9883\n",
      "Epoch 160/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13437.6719 - r2: 0.9930 - M: 39981.1445 - val_loss: 12036.7695 - val_r2: 0.9930 - val_M: 36460.2656\n",
      "Epoch 161/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13436.0703 - r2: 0.9930 - M: 39973.0273 - val_loss: 12008.8574 - val_r2: 0.9930 - val_M: 36307.6016\n",
      "Epoch 162/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13431.1445 - r2: 0.9930 - M: 40226.1641 - val_loss: 12055.0371 - val_r2: 0.9930 - val_M: 36585.0117\n",
      "Epoch 163/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13427.1553 - r2: 0.9930 - M: 39934.8633 - val_loss: 12091.0234 - val_r2: 0.9930 - val_M: 36333.9688\n",
      "Epoch 164/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13418.0723 - r2: 0.9930 - M: 39916.4258 - val_loss: 12201.6299 - val_r2: 0.9930 - val_M: 36337.6719\n",
      "Epoch 165/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13422.1631 - r2: 0.9930 - M: 39987.7461 - val_loss: 11985.6455 - val_r2: 0.9930 - val_M: 36405.1211\n",
      "Epoch 166/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13417.6328 - r2: 0.9930 - M: 39904.8398 - val_loss: 12039.8105 - val_r2: 0.9930 - val_M: 36318.6602\n",
      "Epoch 167/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13415.1504 - r2: 0.9930 - M: 39929.4883 - val_loss: 11989.5967 - val_r2: 0.9931 - val_M: 36259.8398\n",
      "Epoch 168/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13411.8350 - r2: 0.9930 - M: 39923.2109 - val_loss: 12124.3564 - val_r2: 0.9930 - val_M: 36581.0508\n",
      "Epoch 169/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13406.4844 - r2: 0.9930 - M: 39877.4805 - val_loss: 12193.5586 - val_r2: 0.9930 - val_M: 36688.4258\n",
      "Epoch 170/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13404.5332 - r2: 0.9930 - M: 39882.4297 - val_loss: 12108.2676 - val_r2: 0.9930 - val_M: 36463.9531\n",
      "Epoch 171/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13402.4160 - r2: 0.9930 - M: 39926.2031 - val_loss: 12116.6738 - val_r2: 0.9930 - val_M: 36501.9336\n",
      "Epoch 172/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13400.4004 - r2: 0.9930 - M: 39848.3906 - val_loss: 12052.1758 - val_r2: 0.9930 - val_M: 36289.8750\n",
      "Epoch 173/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13399.9170 - r2: 0.9930 - M: 39878.5312 - val_loss: 12082.4707 - val_r2: 0.9930 - val_M: 36526.7461\n",
      "Epoch 174/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13395.4512 - r2: 0.9930 - M: 39854.6289 - val_loss: 11970.8740 - val_r2: 0.9930 - val_M: 36295.1562\n",
      "Epoch 175/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13392.6963 - r2: 0.9930 - M: 39840.5234 - val_loss: 12035.6396 - val_r2: 0.9930 - val_M: 36361.0859\n",
      "Epoch 176/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13391.4922 - r2: 0.9930 - M: 39842.0000 - val_loss: 11983.3828 - val_r2: 0.9930 - val_M: 36402.8555\n",
      "Epoch 177/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13390.0488 - r2: 0.9930 - M: 39818.7266 - val_loss: 12052.0449 - val_r2: 0.9930 - val_M: 36426.4219\n",
      "Epoch 178/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13386.0254 - r2: 0.9930 - M: 39822.8398 - val_loss: 12090.6006 - val_r2: 0.9930 - val_M: 36484.9219\n",
      "Epoch 179/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13385.7520 - r2: 0.9930 - M: 39828.9648 - val_loss: 12093.5566 - val_r2: 0.9930 - val_M: 36540.5273\n",
      "Epoch 180/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13383.6162 - r2: 0.9930 - M: 39809.1367 - val_loss: 11987.5674 - val_r2: 0.9930 - val_M: 36404.1641\n",
      "Epoch 181/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13382.6787 - r2: 0.9931 - M: 39789.7539 - val_loss: 11998.3203 - val_r2: 0.9931 - val_M: 36177.3164\n",
      "Epoch 182/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13382.3838 - r2: 0.9930 - M: 39816.3281 - val_loss: 12046.7930 - val_r2: 0.9930 - val_M: 36410.4922\n",
      "Epoch 183/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13379.3271 - r2: 0.9931 - M: 39794.7695 - val_loss: 12023.4414 - val_r2: 0.9930 - val_M: 36365.1875\n",
      "Epoch 184/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13378.9033 - r2: 0.9930 - M: 39801.3203 - val_loss: 12004.3281 - val_r2: 0.9930 - val_M: 36373.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13376.8145 - r2: 0.9931 - M: 39786.0977 - val_loss: 12022.3516 - val_r2: 0.9930 - val_M: 36354.1406\n",
      "Epoch 186/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13374.4678 - r2: 0.9930 - M: 39791.5898 - val_loss: 12074.7900 - val_r2: 0.9930 - val_M: 36446.7969\n",
      "Epoch 187/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13375.7568 - r2: 0.9931 - M: 39778.4102 - val_loss: 11983.7148 - val_r2: 0.9930 - val_M: 36295.8320\n",
      "Epoch 188/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13371.8242 - r2: 0.9930 - M: 39859.6992 - val_loss: 12064.4541 - val_r2: 0.9930 - val_M: 36343.5938\n",
      "Epoch 189/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13372.1299 - r2: 0.9931 - M: 39783.3828 - val_loss: 11979.8252 - val_r2: 0.9930 - val_M: 36288.1094\n",
      "Epoch 190/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13371.0312 - r2: 0.9931 - M: 39765.8359 - val_loss: 12018.1582 - val_r2: 0.9930 - val_M: 36315.8008\n",
      "Epoch 191/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13369.2256 - r2: 0.9931 - M: 39746.4727 - val_loss: 12053.1533 - val_r2: 0.9930 - val_M: 36426.3242\n",
      "Epoch 192/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13369.8457 - r2: 0.9931 - M: 39776.0508 - val_loss: 12034.7734 - val_r2: 0.9930 - val_M: 36382.5469\n",
      "Epoch 193/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13368.4414 - r2: 0.9931 - M: 39770.1562 - val_loss: 12013.7930 - val_r2: 0.9930 - val_M: 36310.7383\n",
      "Epoch 194/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13366.0840 - r2: 0.9931 - M: 39769.4062 - val_loss: 11997.2324 - val_r2: 0.9930 - val_M: 36301.2383\n",
      "Epoch 195/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13365.8311 - r2: 0.9931 - M: 39762.9805 - val_loss: 12032.7354 - val_r2: 0.9930 - val_M: 36358.7344\n",
      "Epoch 196/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13364.9619 - r2: 0.9931 - M: 39743.9570 - val_loss: 12025.5469 - val_r2: 0.9930 - val_M: 36364.6055\n",
      "Epoch 197/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13362.5293 - r2: 0.9931 - M: 39750.8125 - val_loss: 12013.8799 - val_r2: 0.9930 - val_M: 36467.5391\n",
      "Epoch 198/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13364.1240 - r2: 0.9931 - M: 39752.5000 - val_loss: 12054.9590 - val_r2: 0.9930 - val_M: 36492.9766\n",
      "Epoch 199/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13363.8047 - r2: 0.9929 - M: 40977.2305 - val_loss: 11976.3223 - val_r2: 0.9930 - val_M: 36340.6016\n",
      "Epoch 200/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13362.9385 - r2: 0.9931 - M: 39775.9219 - val_loss: 12037.2412 - val_r2: 0.9930 - val_M: 36421.7773\n",
      "Epoch 201/210\n",
      "1039/1039 [==============================] - 7s 6ms/step - loss: 13359.9502 - r2: 0.9931 - M: 39742.6797 - val_loss: 12021.5771 - val_r2: 0.9930 - val_M: 36413.0391\n",
      "Epoch 202/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13359.4922 - r2: 0.9931 - M: 39727.1172 - val_loss: 12012.5449 - val_r2: 0.9930 - val_M: 36354.2344\n",
      "Epoch 203/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13358.4502 - r2: 0.9931 - M: 39748.2070 - val_loss: 12025.7012 - val_r2: 0.9930 - val_M: 36390.6875\n",
      "Epoch 204/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13358.0654 - r2: 0.9931 - M: 39729.3789 - val_loss: 12015.9736 - val_r2: 0.9930 - val_M: 36341.3828\n",
      "Epoch 205/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13356.9023 - r2: 0.9931 - M: 39720.7852 - val_loss: 12007.1016 - val_r2: 0.9930 - val_M: 36333.0195\n",
      "Epoch 206/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13355.2754 - r2: 0.9931 - M: 39761.6406 - val_loss: 12018.0000 - val_r2: 0.9930 - val_M: 36376.5508\n",
      "Epoch 207/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13355.3770 - r2: 0.9931 - M: 39738.4297 - val_loss: 12014.1338 - val_r2: 0.9930 - val_M: 36350.1484\n",
      "Epoch 208/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13354.8662 - r2: 0.9931 - M: 39721.8945 - val_loss: 12007.2441 - val_r2: 0.9930 - val_M: 36351.0156\n",
      "Epoch 209/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13354.6348 - r2: 0.9931 - M: 39736.0352 - val_loss: 12029.2148 - val_r2: 0.9930 - val_M: 36379.8789\n",
      "Epoch 210/210\n",
      "1039/1039 [==============================] - 6s 6ms/step - loss: 13354.2217 - r2: 0.9931 - M: 39731.9453 - val_loss: 12020.3105 - val_r2: 0.9930 - val_M: 36379.9023\n"
     ]
    }
   ],
   "source": [
    "mdl = MyModel1(w_to_coef(w, 16), nparticles, ndim, n_out, 32, 16)\n",
    "h = decay_train_huber(mdl,X1,X2,Y1,Y2, nepochs = 200, delta = delta) # delta is the parameter for huber loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f4615",
   "metadata": {},
   "source": [
    "Let's get the damping coeffient for all particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ddcf5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particles descriptors [-0.12295111  0.23337628  0.23149179  0.23492663 -0.05348454  0.222217\n",
      " -0.09414835 -0.15795815 -0.16096936 -0.06379275 -0.06908008  0.23170218\n",
      " -0.2676934  -0.0751785  -0.08845761]\n",
      "gamma for all particles [0.6948838  0.9887138  0.98747504 0.98969525 0.7011998  0.98061395\n",
      " 0.6994293  0.6817341  0.68006456 0.7009594  0.7008153  0.98761594\n",
      " 0.5302875  0.700607   0.6998923 ]\n"
     ]
    }
   ],
   "source": [
    "descriptors = X1[0][0,0,3::4]\n",
    "print('particles descriptors', descriptors.numpy())\n",
    "gamma = mdl.g_w(descriptors[...,tf.newaxis])[...,0].numpy()\n",
    "print('gamma for all particles', gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbe9f3",
   "metadata": {},
   "source": [
    "Now let's predict environmental force. Note that the unit is 100mm/s^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4051735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confinement force has two element, x and y component, as described in the paper\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.4558854, -1.8705156]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1\n",
    "y = 1\n",
    "z = 0\n",
    "s = -0.12\n",
    "print('the confinement force has two element, x and y component, as described in the paper')\n",
    "get_confinement(mdl,x,y,z,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e57db",
   "metadata": {},
   "source": [
    "Interaction force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7393be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction force magnitude is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.55997932])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = 0\n",
    "z2 = 0\n",
    "rho = 0.5\n",
    "s1 = -0.12\n",
    "s2 = 0.23\n",
    "print('interaction force magnitude is')\n",
    "get_interaction(mdl, z1, z2, rho,s1, s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
